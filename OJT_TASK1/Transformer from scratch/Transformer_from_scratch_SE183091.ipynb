{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DxUQl90uVivs"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from typing import Any\n",
        "import torch.nn as nn\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic=True\n",
        "\n",
        "class InputEmbeddings(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int):\n",
        "        super().__init__()\n",
        "        self.d_model=d_model # Dimension of vectors (512)\n",
        "        self.vocab_size=vocab_size # Size of the vocabulary\n",
        "        self.embedding=nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embedding(x)*math.sqrt(self.d_model) # normalizing the variance of the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dkr-7StHVivy"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model:int, seq_len:int, dropout:float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model=d_model # Dimensionality of the model\n",
        "        self.seq_len=seq_len # Maximum sequence length\n",
        "        self.dropout=nn.Dropout(dropout) # dropout layer to prevent overfitting\n",
        "\n",
        "        # creating a positional ecoding matrix of shape (seq_len, d_model) filled with zeros\n",
        "        pe=torch.zeros(seq_len, d_model)\n",
        "\n",
        "        # creating a tensor representing positions (0 to seq_len -1)\n",
        "        position=torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # transforming `position` into a 2D tensor[seq_len,1]\n",
        "\n",
        "        # creating te division term for the positional encoding formula\n",
        "        div_term=torch.exp(torch.arange(0, d_model, 2).float()*(-math.log(10000.0)/d_model))\n",
        "\n",
        "        # apply sine to even indices in pe\n",
        "        pe[:,0::2]=torch.sin(position*div_term)\n",
        "\n",
        "        # apply cosine to odd indices in pe\n",
        "        pe[:,1::2]=torch.cos(position*div_term)\n",
        "\n",
        "        # adding an extra dimension at the beginning of pe matrix for batch handling\n",
        "        pe=pe.unsqueeze(0)\n",
        "\n",
        "        # registering 'pe' as buffer, buffer is a tensor not considered as a model parameter\n",
        "        self.register_buffer('pe',pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # adding positional encoding to the input tensor X\n",
        "        x=x+(self.pe[:,:x.shape[1],:].requires_grad_(False))\n",
        "        return self.dropout(x) # dropout for regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bzMbJrTXVivz"
      },
      "outputs": [],
      "source": [
        "# creating layer normalization\n",
        "class LayerNormalization(nn.Module):\n",
        "    # we define epsilon as 0.000001 to avoid division by zero\n",
        "    def __init__(self, eps: float=10**-6)-> None:\n",
        "        super().__init__()\n",
        "        self.eps=eps\n",
        "\n",
        "        # we define alpha as a trainable parameter and initialize it with ones\n",
        "        self.alpha=nn.Parameter(torch.ones(1)) # One-dimensional tensor that will be used to scale the input data\n",
        "\n",
        "        # we define bias as a trainable parameter and initialize it with zeros\n",
        "        self.bias=nn.Parameter(torch.zeros(1)) # One-dimensional tensor that will be added to the input data\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean=x.mean(dim=-1, keepdim=True) # computing the mean of the input data. Keeping the number of dimensions unchanged\n",
        "        std=x.std(dim=-1, keepdim=True) # computing the standard deviation of the input data. Keeping the number of dimensions unchanged\n",
        "\n",
        "        # returning the normalized input\n",
        "        return self.alpha*(x-mean)/(std+self.eps)+self.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ypSImJEnViv0"
      },
      "outputs": [],
      "source": [
        "class FeedForwardBlock(nn.Module):\n",
        "    def __init__(self,d_model:int, d_ff:int, dropout:float) -> None:\n",
        "        super().__init__()\n",
        "        # First lienar transformation\n",
        "        self.linear_1=nn.Linear(d_model, d_ff) # W1 & b1\n",
        "        self.dropout=nn.Dropout(dropout) # Dropout to prevent overfitting\n",
        "\n",
        "        # Second linear transformation\n",
        "        self.linear_2=nn.Linear(d_ff, d_model) # W2 & b2\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, d_ff) --> (batch, seq_len, d_model)\n",
        "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "owRQSQ6gViv1"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model: int, h:int, dropout:float)-> None: # h= number of heads\n",
        "        super().__init__()\n",
        "        self.d_model=d_model\n",
        "        self.h=h\n",
        "\n",
        "        # we ensure that the dimensions of the model is divisible by the number of heads\n",
        "        assert d_model %h==0, 'd_model is not divisible by h'\n",
        "\n",
        "        # d_k is the dimension of each attention head's key, query, and values vectors\n",
        "        self.d_k =d_model // h # d_k formula, like in the original paper\n",
        "\n",
        "        # degining the weight matrices\n",
        "        self.w_q=nn.Linear(d_model, d_model) # W_|q\n",
        "        self.w_k=nn.Linear(d_model, d_model) # W_k\n",
        "        self.w_v=nn.Linear(d_model, d_model) # W_v\n",
        "        self.w_o=nn.Linear(d_model, d_model) # W_o\n",
        "\n",
        "        self.dropout=nn.Dropout(dropout) # Dropout layer to avoid overfitting\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(query, key, value, mask, dropout:nn.Dropout): # mask=>when we certain words to not interact with others, we hide them\n",
        "        d_k=query.shape[-1] # the last dimension of query, key and value\n",
        "\n",
        "        # we calculate the Attention(Q,K,V) as in the formula in the image above\n",
        "        attention_scores=(query@key.transpose(-2, -1))/math.sqrt(d_k) # @=matrix multiplication sign in PyTorch\n",
        "\n",
        "        # before applying the softmax, we apply the mask to hide some interactions between words\n",
        "        if mask is not None:\n",
        "            attention_scores.masked_fill_(mask==0, -1e9) # replace each value where mask is equal to 0 by -1e9\n",
        "        attention_scores=attention_scores.softmax(dim=-1) # applying softmax\n",
        "        if dropout is not None:\n",
        "            attention_scores=dropout(attention_scores) # we apply dropout to prevent overfitting\n",
        "\n",
        "        return (attention_scores @ value), attention_scores # multiply the output matrix by the V matrix, as in the formula\n",
        "\n",
        "    def forward(self, q,k,v, mask):\n",
        "        query=self.w_q(q) # Q' matrix\n",
        "        key=self.w_k(k) # K' matrix\n",
        "        value=self.w_v(v) # V' matrix\n",
        "\n",
        "        # splitting results into smaller matrices for the different heads\n",
        "        # splitting embeddings (third dimension) into h parts\n",
        "\n",
        "        # Transpose => bring the head to the second dimension\n",
        "        query=query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1,2)\n",
        "\n",
        "        # Transpose => bring the head to the second dimension\n",
        "        key=key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1,2)\n",
        "\n",
        "        # Transpose => bring the head to the second dimension\n",
        "        value=value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1,2)\n",
        "\n",
        "        # obtaining the output and the attention scores\n",
        "        x, self.attention_scores=MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "        # obtaining the H matrix\n",
        "        x=x.transpose(1,2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
        "\n",
        "        # multiply the H matrix by the weight matrix W_o, resulting in the MH-A matrix\n",
        "        return self.w_o(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y8r2C1jgViv2"
      },
      "outputs": [],
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "    def __init__(self, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        # we use a dropout layer to prevent overfitting\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "        # we use a normalization layer\n",
        "        self.norm=LayerNormalization()\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        # we normalize the input and add it to the original input x`. This creates the residual connection process\n",
        "        return x+self.dropout(sublayer(self.norm(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Tka0h8jCViv2"
      },
      "outputs": [],
      "source": [
        "# building encoder block\n",
        "class EncoderBlock(nn.Module):\n",
        "    # this block takes in the MultiHeadAttentionBlock and FeedForwardBlock, as well as the dropout rate for the residual connections.\n",
        "    def __init__(self, self_attention_block: MultiHeadAttentionBlock, feed_forward_block:FeedForwardBlock, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        #Strong the self-attention block and feed-forward block\n",
        "        self.self_attention_block=self_attention_block\n",
        "        self.feed_forward_block=feed_forward_block\n",
        "        # 2 residual connections with dropout\n",
        "        self.residual_connections=nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        # Applying the first residual connection with the self-attention block\n",
        "        # Three x corresponding to query, key and value inputs plus source mask\n",
        "        x=self.residual_connections[0](x,lambda x: self.self_attention_block(x,x,x,src_mask))\n",
        "\n",
        "        # Appplying the second residual connection with the feed-forward block\n",
        "        x=self.residual_connections[1](x, self.feed_forward_block)\n",
        "\n",
        "        # output tensor after applying self-attention and feed-forward layers with residual connections\n",
        "        return x\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, layers: nn.ModuleList)-> None:\n",
        "        super().__init__()\n",
        "        self.layers=layers # storing the EncoderBlocks\n",
        "        # layer for the normalization of the output of the encoder layers\n",
        "        self.norm=LayerNormalization()\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # Iterating over each EncoderBlock stored in self.layers\n",
        "        for layer in self.layers:\n",
        "            # Applying each EncoderBlock to the input tensot 'x'\n",
        "            x=layer(x, mask)\n",
        "        return self.norm(x) # Normalizing output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VpSyWFclViv3"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    # the DecoderBlock takes in two MultiHeadAttentionBlock. One is self-attention, while the other is cross-attention.\n",
        "    # it also takes in the feed-forward block and the dropout rate\n",
        "    def __init__(self, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float)->None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block=self_attention_block\n",
        "        self.cross_attention_block=cross_attention_block\n",
        "        self.feed_forward_block=feed_forward_block\n",
        "        # list of three Residual Connection with dropout rate\n",
        "        self.residual_connections=nn.ModuleList([ResidualConnection(dropout) for _ in range(3)])\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        # self-attention block with query, key and value plus the target language mask\n",
        "        x=self.residual_connections[0](x, lambda x: self.self_attention_block(x,x,x, tgt_mask))\n",
        "        # the cross-attention block using two `encoder_output` for key and value plus the source language mask. It also takes in `x` for Decoder queries\n",
        "        x=self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n",
        "\n",
        "        # feed-forward block with residual connections\n",
        "        x=self.residual_connections[2](x,self.feed_forward_block)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, layers: nn.ModuleList)-> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers=layers\n",
        "        self.norm=LayerNormalization()\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x=layer(x, encoder_output, src_mask, tgt_mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k-EoTnt8Viv4"
      },
      "outputs": [],
      "source": [
        "class ProjectionLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int)-> None: # model dimension and the size of the output vocabulary\n",
        "        super().__init__()\n",
        "        # linear layer for projecting the feature space of `d_model` to the output space of `vocab_size`\n",
        "        self.proj=nn.Linear(d_model, vocab_size)\n",
        "    def forward(self, x):\n",
        "        # applying the log Softmax function to the output\n",
        "        return torch.log_softmax(self.proj(x), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z9EdsHYxViv4"
      },
      "outputs": [],
      "source": [
        "# Creating the Transformer Architecture\n",
        "class Transformer(nn.Module):\n",
        "    # This takes in the encoder and decoder, as well the embeddings for the source and target language.\n",
        "    # It also takes in the POsitional Encoding for the source and target language, as well as the projection layer\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding, projection_layer:ProjectionLayer) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder=encoder\n",
        "        self.decoder=decoder\n",
        "        self.src_embed=src_embed\n",
        "        self.tgt_embed=tgt_embed\n",
        "        self.src_pos=src_pos\n",
        "        self.tgt_pos=tgt_pos\n",
        "        self.projection_layer=projection_layer\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        # applying source embeddings to the input source language\n",
        "        src=self.src_embed(src)\n",
        "        # applying source positional encoding to the soruce embeddings\n",
        "        src=self.src_pos(src)\n",
        "        # returning the source embeddings plus a source mask to prevent attention to certain elements\n",
        "        return self.encoder(src, src_mask)\n",
        "\n",
        "    def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
        "        tgt=self.tgt_embed(tgt) # applying target embeddings to the input target language (tgt)\n",
        "        tgt=self.tgt_pos(tgt) # applying target positional encoding to the target embeddings\n",
        "\n",
        "        # return the target embeddings, the output of the encoder, and both source and target masks\n",
        "        # The target mask ensures that the model won't see future elements of the sequence\n",
        "        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
        "\n",
        "    # applying projection layer with the Softmax function to the Decoder output\n",
        "    def project(self, x):\n",
        "        return self.projection_layer(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R-IONjBqViv5"
      },
      "outputs": [],
      "source": [
        "def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len:int, tgt_seq_len:int, d_model:int=512, N:int=6, h:int=8, dropout:float=0.1, d_ff:int=2048)->Transformer:\n",
        "    # creating embedding layers\n",
        "    src_embed=InputEmbeddings(d_model, src_vocab_size) # source language (Source Vocabulary to 512-dimensional vectors)\n",
        "    tgt_embed=InputEmbeddings(d_model, tgt_vocab_size) # target langauge (Target vocabulary to 512-dimensional vectors)\n",
        "\n",
        "    # creating positional encoding layers\n",
        "    src_pos=PositionalEncoding(d_model, src_seq_len, dropout)\n",
        "    tgt_pos=PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
        "\n",
        "    # creating EncoderBlocks\n",
        "    encoder_blocks=[]\n",
        "    for _ in range(N):\n",
        "        encoder_self_attention_block=MultiHeadAttentionBlock(d_model, h, dropout) # self-attention\n",
        "        feed_forward_block=FeedForwardBlock(d_model, d_ff, dropout) # feedforward\n",
        "\n",
        "        # combine layers into an EncoderBlock\n",
        "        encoder_block=EncoderBlock(encoder_self_attention_block, feed_forward_block, dropout)\n",
        "        encoder_blocks.append(encoder_block) # appending EncoderBlock to the list of EncoderBlocks\n",
        "\n",
        "    # creating decoder blocks\n",
        "    decoder_blocks=[]\n",
        "    for _ in range(N):\n",
        "        decoder_self_attention_block=MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        decoder_cross_attention_block=MultiHeadAttentionBlock(d_model, h, dropout) # cross-attention\n",
        "        feed_forward_block=FeedForwardBlock(d_model, d_ff, dropout) # feedforward\n",
        "\n",
        "        # combining layers into a DecoderBlock\n",
        "        decoder_block=DecoderBlock(decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)\n",
        "        decoder_blocks.append(decoder_block) # appending DecoderBlock and DecoderBlocks lists\n",
        "\n",
        "    # creating the Encoder and Decoder by using the EncoderBlocks and DecoderBlocks lists\n",
        "    encoder=Encoder(nn.ModuleList(encoder_blocks))\n",
        "    decoder=Decoder(nn.ModuleList(decoder_blocks))\n",
        "\n",
        "    # Creating projection layer\n",
        "    projection_layer=ProjectionLayer(d_model, tgt_vocab_size) # map the output of Decoder to the Target Vocabulary Space\n",
        "\n",
        "    # crating the transformer by combining everything above\n",
        "    transformer=Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
        "\n",
        "    # Initialize the parameters\n",
        "    for p in transformer.parameters():\n",
        "        if p.dim()>1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    # Assembled and initialized Transformer, Ready to be trained and validated!\n",
        "    return transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iqCnryhYViv5"
      },
      "outputs": [],
      "source": [
        "def get_all_sentences(ds, lang):\n",
        "    for pair in ds:\n",
        "        yield pair['translation'][lang]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w7Ay2WWViv6",
        "outputId": "61c99ec1-e6c7-40ee-a514-da6cc1420ebd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kWdTs8HQViv6"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch\n",
        "\n",
        "# Function to load dataset and tokenizer\n",
        "def build_tokenizer(config, ds, lang):\n",
        "    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n",
        "\n",
        "    if not Path.exists(tokenizer_path):\n",
        "        tokenizer = Tokenizer(WordLevel(unk_token='[UNK]'))\n",
        "        tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "        trainer = WordLevelTrainer(special_tokens=['[UNK]', '[PAD]', '[SOS]', '[EOS]'], min_frequency=2)\n",
        "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
        "        tokenizer.save(str(tokenizer_path))\n",
        "    else:\n",
        "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NXPLMj3JViv_"
      },
      "outputs": [],
      "source": [
        "def casual_mask(size):\n",
        "    # creating a square matrix of dimensions 'size*size' filled with ones\n",
        "    mask=torch.triu(torch.ones(1, size, size), diagonal=1).type(torch.int)\n",
        "    return mask==0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0r6pYHYYViv_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class BilingualDataset(Dataset):\n",
        "    # This takes in the dataset containing sentence pairs, the tokenizers for target and source language, and the strings of souce and target languages\n",
        "    # `seq_len` defines the sequence length for both languages\n",
        "    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.seq_len=seq_len\n",
        "        self.ds=ds\n",
        "        self.tokenizer_src=tokenizer_src\n",
        "        self.tokenizer_tgt=tokenizer_tgt\n",
        "        self.src_lang=src_lang\n",
        "        self.tgt_lang=tgt_lang\n",
        "\n",
        "        # defining special tokens by using the targte language tokenizer\n",
        "        self.sos_token=torch.tensor([tokenizer_tgt.token_to_id('[SOS]')], dtype=torch.int64)\n",
        "        self.eos_token=torch.tensor([tokenizer_tgt.token_to_id('[EOS]')], dtype=torch.int64)\n",
        "        self.pad_token=torch.tensor([tokenizer_tgt.token_to_id('[PAD]')], dtype=torch.int64)\n",
        "\n",
        "    # Total number os instances in the dataset (some pairs are larger than others)\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    # using the index to retrive source and target texts\n",
        "    def __getitem__(self, index:Any)-> Any:\n",
        "        src_target_pair=self.ds[index]\n",
        "        src_text=src_target_pair['translation'][self.src_lang]\n",
        "        tgt_text=src_target_pair['translation'][self.tgt_lang]\n",
        "\n",
        "        # tokenizing source and target texts\n",
        "        enc_input_tokens=self.tokenizer_src.encode(src_text).ids\n",
        "        dec_input_tokens=self.tokenizer_tgt.encode(tgt_text).ids\n",
        "\n",
        "        # computing how many padding tokens need to be added to the tokenized texts source tokens\n",
        "        enc_num_padding_tokens=self.seq_len-len(enc_input_tokens)-2 # subtracting the two '[EOS]' and '[SOS]' special tokens\n",
        "\n",
        "        # target tokens\n",
        "        dec_num_padding_tokens=self.seq_len-len(dec_input_tokens)-1 # subtracting the '[SOS]' special token\n",
        "\n",
        "        # If the texts exceed the 'seq_len' allowed, it will raise an error. This means that one of the sentences in the pair is too long to be processed\n",
        "        # given the current sequence length limit(this will be defined in the config dictionary below)\n",
        "        if enc_num_padding_tokens<0 or dec_num_padding_tokens<0:\n",
        "            raise ValueError('Sentence is too long')\n",
        "\n",
        "        # building the encoder input tensor by combining several elements\n",
        "        encoder_input=torch.cat([\n",
        "            self.sos_token, # inserting the '[SOS]' token\n",
        "            torch.tensor(enc_input_tokens, dtype=torch.int64), # inserting the tokenized source text,\n",
        "            self.eos_token, # inserting the '[EOS]' token\n",
        "            torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64) # adding padding tokens\n",
        "        ])\n",
        "\n",
        "        # building the decoder input tensor by combining several elements\n",
        "        decoder_input=torch.cat([\n",
        "            self.sos_token, # inserting the '[SOS]' token\n",
        "            torch.tensor(dec_input_tokens, dtype=torch.int64), # indersting the tokenized target text\n",
        "            torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64) # adding padding tokens\n",
        "        ])\n",
        "\n",
        "        # creating a label tensor, the expected output for training the model\n",
        "        label=torch.cat([\n",
        "            torch.tensor(dec_input_tokens, dtype=torch.int64), # inserting the tokenized targate text\n",
        "            self.eos_token, # inserting the '[EOS]' token\n",
        "            torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64) # adding padding tokens\n",
        "        ])\n",
        "\n",
        "        # Ensuring that the length of each tensor above is equal to the defined `seq_len`\n",
        "        assert encoder_input.size(0)==self.seq_len\n",
        "        assert decoder_input.size(0)==self.seq_len\n",
        "        assert label.size(0)==self.seq_len\n",
        "\n",
        "        return {\n",
        "            'encoder_input': encoder_input,\n",
        "            'decoder_input': decoder_input,\n",
        "            'encoder_mask': (encoder_input!=self.pad_token).unsqueeze(0).unsqueeze(0).int(),\n",
        "            'decoder_mask': (decoder_input!=self.pad_token).unsqueeze(0).unsqueeze(0).int() & casual_mask(decoder_input.size(0)),\n",
        "            'label':label,\n",
        "            'src_text': src_text,\n",
        "            'tgt_text': tgt_text\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "4f42ea16575c4423beb7d2d0d29271e3",
            "d7aaabe427fe46868f03392f8d565f5e",
            "183f09a6430d4c81baf03a54e2e68cdb",
            "9a2b081a47094695b1aaad9804e1cf52",
            "746311408cd44e3dbf370b801f26d52d",
            "2f1a2bd377414295a0c50686894e170c",
            "499f02619b2e49859e4d33c436995291",
            "33fcd03fc05645e2bccb4db9cf4f0d7b",
            "d0e137eaf81d40f3ba7ce76999f3874c",
            "5af8555c158f442ab297494503f7b5f0",
            "b1dc197e93a24d22b3b14a5a94a14e56",
            "0d81034b50304c5fbc1618f664bdb181",
            "912325d4971249ae838fa013a98dc92a",
            "c7e2426ee92d4bcea4e14a348dbc0189",
            "796933cba8d94d8cb6d6656798fd891b",
            "936f7ede730642f7bc6ddfb6dbd8457c",
            "e17b5c25bdb146b3831b9f6900c6cc52",
            "2b46320894e44a8195d7e6fcf2e05216",
            "41a3dc5666b749639abdf2d9cf84f40d",
            "19b37d3a41a84204a9ec34fe7e147e45",
            "9a44a1ceba204ecab13a47ab8d7625b7",
            "3aa8e88f544543a78426b145c4bbe659",
            "88c005f7f203459c8bffd95dc9a407c9",
            "285b9f6076774ff3bc2798554f6ec06f",
            "24e3cdef531b4020989366eba22e09ef",
            "aed9a064ab374cf2b4061f177f87cc03",
            "017760bb2a3546259793eb5226c7d0fa",
            "e2d4fe257a414a9fbd61e6deb4db215f",
            "4af75a10d63e43a2a33025bcaeb5a6cf",
            "99bf4c657d1a4bafa847e1ac5fb41733",
            "b50113e248d64de39a9edd93d3d94b68",
            "eb575858b49e4d52bfa6ced2267508b7",
            "90ea3ded66054cd9ad13c8f955ff5db6"
          ]
        },
        "id": "k0grW35CViwA",
        "outputId": "8930dd6a-a8e9-4c3b-a86f-3504cbfe045d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f42ea16575c4423beb7d2d0d29271e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d81034b50304c5fbc1618f664bdb181",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88c005f7f203459c8bffd95dc9a407c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/127085 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "def get_ds(config):\n",
        "    ds_raw = load_dataset('opus_books', f'{config[\"lang_src\"]}-{config[\"lang_tgt\"]}', split='train')\n",
        "\n",
        "    tokenizer_src = build_tokenizer(config, ds_raw, config['lang_src'])\n",
        "    tokenizer_tgt = build_tokenizer(config, ds_raw, config['lang_tgt'])\n",
        "\n",
        "    train_ds_size = int(0.9 * len(ds_raw))\n",
        "    val_ds_size = len(ds_raw) - train_ds_size\n",
        "    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n",
        "\n",
        "    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "\n",
        "    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
        "    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)\n",
        "\n",
        "    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt\n",
        "# Configuration dictionary\n",
        "config = {\n",
        "    \"lang_src\": \"en\",  # Source language (English)\n",
        "    \"lang_tgt\": \"fr\",  # Target language (French)\n",
        "    \"tokenizer_file\": \"./tokenizer_{0}.json\",  # Path to save the tokenizer\n",
        "    \"seq_len\": 128,  # Maximum sequence length\n",
        "    \"batch_size\": 32  # Batch size for training\n",
        "}\n",
        "\n",
        "# Get dataset and dataloaders\n",
        "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "twzeythxViwB"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
        "    # retrieving the indices from the start and end of sequences of the target tokens\n",
        "    sos_idx=tokenizer_tgt.token_to_id('[SOS]')\n",
        "    eos_idx=tokenizer_tgt.token_to_id('[EOS]')\n",
        "\n",
        "    # computing the output of the encoder for the source sequence\n",
        "    encoder_output=model.encode(source, source_mask)\n",
        "    # initializing the decoder input with the Start of Sentence token\n",
        "    decoder_input=torch.empty(1,1).fill_(sos_idx).type_as(source).to(device)\n",
        "\n",
        "    # looping until the `max_len`, maximum length is reached\n",
        "    while True:\n",
        "        if decoder_input.size(1)==max_len:\n",
        "            break\n",
        "\n",
        "        # building a mask for decoder input\n",
        "        decoder_mask=casual_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n",
        "\n",
        "        # calculating the output of the decoder\n",
        "        out=model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
        "\n",
        "        # applying the projection layer to get the probabilities for the next token\n",
        "        prob=model.project(out[:,-1])\n",
        "\n",
        "        # selecting token with the highest probability\n",
        "        _, next_word=torch.max(prob, dim=1)\n",
        "        decoder_input=torch.cat([decoder_input, torch.empty(1,1).type_as(source).fill_(next_word.item()).to(device)], dim=1)\n",
        "\n",
        "        # if the next token is an End of sentence token, we finish the loop\n",
        "        if next_word==eos_idx:\n",
        "            break\n",
        "\n",
        "    # sequence of tokens generated by the decoder\n",
        "    return decoder_input.squeeze(0)\n",
        "\n",
        "\n",
        "# defining function to evaluate the model on the validation dataset, num_examples=2, two examples per run\n",
        "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_state, writer, num_examples=2):\n",
        "    model.eval()\n",
        "    count=0 # initializing counter to keep track of how many examples have been processed\n",
        "\n",
        "    console_width=80 # fixed width for printed messages\n",
        "\n",
        "    # creating evaluation loop\n",
        "    with torch.no_grad(): # ensuring that no gradients are computed during this process\n",
        "        for batch in validation_ds:\n",
        "            count+=1\n",
        "            encoder_input=batch['encoder_input'].to(device)\n",
        "            encoder_mask=batch['encoder_mask'].to(device)\n",
        "\n",
        "            # ensuring that the batch_size of the validation set is 1\n",
        "            assert encoder_input.size(0)==1, 'Batch size must be 1 for validation.'\n",
        "\n",
        "            # applying the `greedy_decode` functio to get the model's output of the source text of the input batch\n",
        "            model_out=greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
        "\n",
        "            # retraeving source and target texts from the batch\n",
        "            source_text=batch['src_text'][0]\n",
        "            target_text=batch['tgt_text'][0] # true translation\n",
        "            model_out_text=tokenizer_tgt.decode(model_out.detach().cpu().numpy()) # decoded, human-readable model ouptut\n",
        "\n",
        "            # printing results\n",
        "            print_msg('-'*console_width)\n",
        "            print_msg(f'SOURCE: {source_text}')\n",
        "            print_msg(f'TARGET: {target_text}')\n",
        "            print_msg(f'PREDICTED: {model_out_text}')\n",
        "\n",
        "            # After two examples, we break the loop\n",
        "            if count==num_examples:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hthEflHsViwC"
      },
      "outputs": [],
      "source": [
        "# we pass as parameters the config dictionary, the length of the vocabulary of the source language and the target language\n",
        "def get_model(config, vocab_src_len, vocab_tgt_len):\n",
        "    # loading model using the `build_transformer` function\n",
        "    # we will use the lengths of the source language and atarget language vocabularies, the `seq_len`, and the dimensionality of embeddings\n",
        "    model=build_transformer(vocab_src_len, vocab_tgt_len, config['seq_len'], config['seq_len'], config['d_model'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ODTFXG2SViwC"
      },
      "outputs": [],
      "source": [
        "# define settings for building and training the transfomer model\n",
        "def get_config():\n",
        "    return{\n",
        "        'batch_size':8,\n",
        "        'num_epochs':5,\n",
        "        'lr':10**-4,\n",
        "        'seq_len':350,\n",
        "        'd_model': 512, # dimensions of the embeddings in the transformer. 512 like in the paper\n",
        "        'lang_src':'en',\n",
        "        'lang_tgt':'it',\n",
        "        'model_folder': 'weights',\n",
        "        'model_basename':'tmodel_',\n",
        "        'preload': None,\n",
        "        'tokenizer_file': 'tokenizer_{0}.json',\n",
        "        'experiment_name':'runs/tmodel'\n",
        "    }\n",
        "\n",
        "# function to construct the path for saving and retrieving model weights\n",
        "def get_weights_file_path(config, epoch: str):\n",
        "    model_folder=config['model_folder'] # extracting model folder from the config\n",
        "    model_basename=config['model_basename'] # extracting thQAe base name for model files\n",
        "    model_filename=f'{model_basename}{epoch}.pt'\n",
        "    return str(Path('.')/model_folder/model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "644QIOBWViwD"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "def train_model(config):\n",
        "    device=(torch.device('cuda') if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Using. device {device}')\n",
        "\n",
        "    # creating model directory to store weights\n",
        "    Path(config['model_folder']).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt=get_ds(config)\n",
        "\n",
        "    model=get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
        "\n",
        "    # Tensorboard\n",
        "    writer=SummaryWriter(config['experiment_name'])\n",
        "\n",
        "    # setting up the Adam optimizer with the specified leanring rate from the `config` dictionary plus an epsilon value\n",
        "    optimizer=torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
        "\n",
        "    # initializing epoch and global step variables\n",
        "    initial_epoch=0\n",
        "    global_step=0\n",
        "\n",
        "    # checking if there is a pre-trained model to load\n",
        "    if config['preload']:\n",
        "        model_filename=get_weights_file_path(config, config['preload'])\n",
        "        print(f'Preloading model {model_filename}')\n",
        "\n",
        "        state=torch.load(model_filename)\n",
        "\n",
        "        # sets epoch to the saved in the state plus one, to resume from wher it stopped\n",
        "        initial_epoch=state['epoch']+1\n",
        "        # loading the optimizer state from the saved model\n",
        "        optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "        global_step=state['global_step']\n",
        "\n",
        "    # initializing CrossEntropyLoss function for training\n",
        "    # we ignore padding tokens when computing loss, as they are not relevant for the learning process\n",
        "    # we also apply label_smoothing to prevent overfitting\n",
        "    loss_fn=nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "\n",
        "    for epoch in range(initial_epoch, config['num_epochs']):\n",
        "        batch_iterator=tqdm(train_dataloader, desc=f'Professing epoch {epoch:02d}')\n",
        "\n",
        "        for batch in batch_iterator:\n",
        "            model.train()\n",
        "\n",
        "            # loading input data and masks onto the GPU\n",
        "            encoder_input=batch['encoder_input'].to(device)\n",
        "            decoder_input=batch['decoder_input'].to(device)\n",
        "            encoder_mask=batch['encoder_mask'].to(device)\n",
        "            decoder_mask=batch['decoder_mask'].to(device)\n",
        "\n",
        "            # runing tensors through the transformer\n",
        "            encoder_output=model.encode(encoder_input, encoder_mask)\n",
        "            decoder_output=model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "            proj_output=model.project(decoder_output)\n",
        "\n",
        "            # loading the target labels onto the GPU\n",
        "            label=batch['label'].to(device)\n",
        "\n",
        "            # computing loss between model's output and true labels\n",
        "            loss=loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
        "\n",
        "            # updating progress bar\n",
        "            batch_iterator.set_postfix({f'loss':f'{loss.item():6.3f}'})\n",
        "\n",
        "            writer.add_scalar('train loss', loss.item(), global_step)\n",
        "            writer.flush()\n",
        "\n",
        "            # performing backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # clearing the gradients to prepare for the next bacth\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            global_step+=1 # updating global step count\n",
        "\n",
        "\n",
        "        # we run the 'run_validation' function at the end of each epoch to evaluate model performance\n",
        "        run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: batch_iterator.write(msg), global_step, writer)\n",
        "\n",
        "        # saving model\n",
        "        model_filename=get_weights_file_path(config, f'{epoch:02d}')\n",
        "\n",
        "        # writting current model state to the `model_filename`\n",
        "        torch.save({\n",
        "            'epoch':epoch, # current epoch\n",
        "            'model_state_dict': model.state_dict(), # current model state\n",
        "            'optimizer_state_dict': optimizer.state_dict(), # current optimizer state\n",
        "            'global_step': global_step # current global step\n",
        "        }, model_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899,
          "referenced_widgets": [
            "1b69257d36d14765a4e9631ecf381776",
            "f66b0b60fc654586bf906c3a61823016",
            "00cfa3469d0a48cfa64c51c0e0658b26",
            "3b91e38bc3f6439b87d9039481a8e8ec",
            "fcd01726f1974bfbaf3df22e27298090",
            "b6057770f57e4213aa39b6d598a62a7d",
            "ea624b6940df4e42ae305a0d39ce19bc",
            "9cb732b3ed1a48069fe683ee9e503004",
            "c2d31438f4994b6ba30cb181ccc54331",
            "50184cc3ae7c49f68e601506ce04fd1a",
            "dfddf0c1fcd94cd5989f6a49b1a0f153",
            "477e12300a9b4265a62f06fa6175a290",
            "b2a765d9f4974feaa8f6e258de704bf7",
            "3d175dc6f4dd46e79a5168c55adcc202",
            "6ce0d43376654cfdad4bce4a2cef52cc",
            "0d426071c5e9439196074afa121ca488",
            "3627508576104e62acbdc7fafc752f22",
            "6c1f5f6aaea44c15bf69ad3c015bd432",
            "f7d330f313a4496a8fc2e5c50aa63f8d",
            "7a3a378f1c494fe8b007874830e2cb10",
            "3173933f8fad4448bc02fcfa97857f62",
            "6f298c3d162046da962fac2bfb82f6bd"
          ]
        },
        "id": "HwB5TXVyViwD",
        "outputId": "f8b77204-e833-466a-faa5-2dc884a316cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using. device cuda\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b69257d36d14765a4e9631ecf381776",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/5.73M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "477e12300a9b4265a62f06fa6175a290",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Professing epoch 00: 100%|██████████| 3638/3638 [26:43<00:00,  2.27it/s, loss=5.810]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "SOURCE: CHAPTER II\n",
            "TARGET: II\n",
            "PREDICTED: \n",
            "--------------------------------------------------------------------------------\n",
            "SOURCE: The horse followed,--a tall steed, and on its back a rider.\n",
            "TARGET: Il cavallo veniva dietro ed era montato da un cavaliere.\n",
            "PREDICTED: La sua sua volta era stata , e a , e .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Professing epoch 01: 100%|██████████| 3638/3638 [26:42<00:00,  2.27it/s, loss=5.024]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "SOURCE: It was necessary that Cyrus should find the Persians discontented with the government of the Medes, and the Medes soft and effeminate through their long peace.\n",
            "TARGET: Bisognava che Ciro trovassi e' Persi malcontenti dello imperio de' Medi, e li Medi molli et effeminati per la lunga pace.\n",
            "PREDICTED: Era un ’ altra cosa che non si era stato un ’ altra parte di , e , e , e , e , e , e , e .\n",
            "--------------------------------------------------------------------------------\n",
            "SOURCE: And you will marry him, Jane, won't you? And then he will stay in England.\"\n",
            "TARGET: Voi lo sposerete, Jane, non è vero? ed egli rimarrà in Inghilterra.\n",
            "PREDICTED: E tu , perché non vi , Jane ?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Professing epoch 02: 100%|██████████| 3638/3638 [26:41<00:00,  2.27it/s, loss=5.826]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "SOURCE: My raft was now strong enough to bear any reasonable weight. My next care was what to load it with, and how to preserve what I laid upon it from the surf of the sea; but I was not long considering this.\n",
            "TARGET: La mia zattera era portata ora a tale stato, da poter sostenere qualunque ragionevole peso; onde gli altri miei pensieri poi furono volti su le cose di cui l’avrei caricata e sul modo di preservarle dalla risacca del mare; ma su questo secondo punto non fermai a lungo le mie considerazioni.\n",
            "PREDICTED: il mio moschetto , perchè il mio padre era stato in cui era stato stato in cui il mio padre , e che il mio padre era stato stato di , e che non mi era stato in tal modo di .\n",
            "--------------------------------------------------------------------------------\n",
            "SOURCE: I ought to have said to him, \"that your farming is conducted like that old man's: that you have found means to interest the labourers in the results of their work, and have found improvements which they must recognize as such – then, without impoverishing the soil, you will get double and treble the crops you get now.\n",
            "TARGET: Immaginatevi, avrei dovuto dirgli, che da voi l’azienda vada come dal vecchio; che voi abbiate trovato il modo di interessare i lavoratori al buon successo del lavoro e che abbiate trovato nei perfezionamenti quello stesso punto di mezzo che essi apprezzano, e che infine, senza isterilire il suolo, ricaviate il doppio o il triplo in confronto di prima.\n",
            "PREDICTED: \" Se lo so , se ne , se è vero , che è stato di Dio , che tu non , e che vi , e che si , e che si , e che si , e che si , e che si , e che si , e che si , e che si , e che si , se non si , e che si , e che si , e che si , e che si , , e che non , e che si , e , e a , e che si , se non .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Professing epoch 03: 100%|██████████| 3638/3638 [26:40<00:00,  2.27it/s, loss=4.798]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "SOURCE: 'Nothing to do, nothing to do!' she muttered with tears in her eyes. 'No, there is something else to do,' she said.\n",
            "TARGET: — Niente da fare, niente da fare... — ripeteva lei con le lacrime agli occhi. — No, non niente da fare! — disse.\n",
            "PREDICTED: — Non è nulla di nulla — disse , sorridendo , sorridendo , e , senza aver parlato . — No , è così che è così così — disse .\n",
            "--------------------------------------------------------------------------------\n",
            "SOURCE: 'Why, why?'\n",
            "TARGET: — Perché, perché?\n",
            "PREDICTED: — Perché ?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Professing epoch 04: 100%|██████████| 3638/3638 [26:41<00:00,  2.27it/s, loss=5.190]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "SOURCE: He was dissatisfied with her because she could not face letting him go when it was necessary (and how strange it was to think that he, who such a short time ago dared not believe in the happiness of her loving him, now felt unhappy because she loved him too much!), and dissatisfied with himself because he had not maintained his authority.\n",
            "TARGET: Era scontento di lei perché non gli aveva permesso di allontanarsi quando era necessario (e come era strano che lui, che, fino a poco tempo addietro, non aveva coraggio di credere ch’ella lo amasse, ora si sentisse infelice perché lo amava troppo!), ed era scontento di sé perché non aveva mostrato carattere.\n",
            "PREDICTED: Era felice di non pensare a se non avesse potuto , e , come se avesse potuto , era stato un ’ altra cosa , che non poteva più bene , che non poteva più bene di lui , e che non poteva e che non avesse potuto .\n",
            "--------------------------------------------------------------------------------\n",
            "SOURCE: I always feel that I am getting no real profit out of my estate and yet I go on...\n",
            "TARGET: Io sento sempre che non c’è un vero tornaconto nella mia azienda, eppure si fa...\n",
            "PREDICTED: Io non sono più contento di , non sono stato in casa mia .\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "\n",
        "if __name__=='__main__':\n",
        "    warnings.filterwarnings('ignore')\n",
        "    config=get_config() #retrieving config settings\n",
        "    train_model(config) # training model with config arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZlZr1SWOViwD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZRoqlfSlAk5"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30648,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00cfa3469d0a48cfa64c51c0e0658b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cb732b3ed1a48069fe683ee9e503004",
            "max": 5726189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2d31438f4994b6ba30cb181ccc54331",
            "value": 5726189
          }
        },
        "017760bb2a3546259793eb5226c7d0fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d426071c5e9439196074afa121ca488": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d81034b50304c5fbc1618f664bdb181": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_912325d4971249ae838fa013a98dc92a",
              "IPY_MODEL_c7e2426ee92d4bcea4e14a348dbc0189",
              "IPY_MODEL_796933cba8d94d8cb6d6656798fd891b"
            ],
            "layout": "IPY_MODEL_936f7ede730642f7bc6ddfb6dbd8457c"
          }
        },
        "183f09a6430d4c81baf03a54e2e68cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33fcd03fc05645e2bccb4db9cf4f0d7b",
            "max": 28064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0e137eaf81d40f3ba7ce76999f3874c",
            "value": 28064
          }
        },
        "19b37d3a41a84204a9ec34fe7e147e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b69257d36d14765a4e9631ecf381776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f66b0b60fc654586bf906c3a61823016",
              "IPY_MODEL_00cfa3469d0a48cfa64c51c0e0658b26",
              "IPY_MODEL_3b91e38bc3f6439b87d9039481a8e8ec"
            ],
            "layout": "IPY_MODEL_fcd01726f1974bfbaf3df22e27298090"
          }
        },
        "24e3cdef531b4020989366eba22e09ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99bf4c657d1a4bafa847e1ac5fb41733",
            "max": 127085,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b50113e248d64de39a9edd93d3d94b68",
            "value": 127085
          }
        },
        "285b9f6076774ff3bc2798554f6ec06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2d4fe257a414a9fbd61e6deb4db215f",
            "placeholder": "​",
            "style": "IPY_MODEL_4af75a10d63e43a2a33025bcaeb5a6cf",
            "value": "Generating train split: 100%"
          }
        },
        "2b46320894e44a8195d7e6fcf2e05216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f1a2bd377414295a0c50686894e170c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3173933f8fad4448bc02fcfa97857f62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fcd03fc05645e2bccb4db9cf4f0d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3627508576104e62acbdc7fafc752f22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa8e88f544543a78426b145c4bbe659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b91e38bc3f6439b87d9039481a8e8ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50184cc3ae7c49f68e601506ce04fd1a",
            "placeholder": "​",
            "style": "IPY_MODEL_dfddf0c1fcd94cd5989f6a49b1a0f153",
            "value": " 5.73M/5.73M [00:00&lt;00:00, 25.8MB/s]"
          }
        },
        "3d175dc6f4dd46e79a5168c55adcc202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7d330f313a4496a8fc2e5c50aa63f8d",
            "max": 32332,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a3a378f1c494fe8b007874830e2cb10",
            "value": 32332
          }
        },
        "41a3dc5666b749639abdf2d9cf84f40d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "477e12300a9b4265a62f06fa6175a290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2a765d9f4974feaa8f6e258de704bf7",
              "IPY_MODEL_3d175dc6f4dd46e79a5168c55adcc202",
              "IPY_MODEL_6ce0d43376654cfdad4bce4a2cef52cc"
            ],
            "layout": "IPY_MODEL_0d426071c5e9439196074afa121ca488"
          }
        },
        "499f02619b2e49859e4d33c436995291": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4af75a10d63e43a2a33025bcaeb5a6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f42ea16575c4423beb7d2d0d29271e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7aaabe427fe46868f03392f8d565f5e",
              "IPY_MODEL_183f09a6430d4c81baf03a54e2e68cdb",
              "IPY_MODEL_9a2b081a47094695b1aaad9804e1cf52"
            ],
            "layout": "IPY_MODEL_746311408cd44e3dbf370b801f26d52d"
          }
        },
        "50184cc3ae7c49f68e601506ce04fd1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af8555c158f442ab297494503f7b5f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c1f5f6aaea44c15bf69ad3c015bd432": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ce0d43376654cfdad4bce4a2cef52cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3173933f8fad4448bc02fcfa97857f62",
            "placeholder": "​",
            "style": "IPY_MODEL_6f298c3d162046da962fac2bfb82f6bd",
            "value": " 32332/32332 [00:00&lt;00:00, 354342.95 examples/s]"
          }
        },
        "6f298c3d162046da962fac2bfb82f6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "746311408cd44e3dbf370b801f26d52d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796933cba8d94d8cb6d6656798fd891b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a44a1ceba204ecab13a47ab8d7625b7",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa8e88f544543a78426b145c4bbe659",
            "value": " 21.0M/21.0M [00:00&lt;00:00, 128MB/s]"
          }
        },
        "7a3a378f1c494fe8b007874830e2cb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88c005f7f203459c8bffd95dc9a407c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_285b9f6076774ff3bc2798554f6ec06f",
              "IPY_MODEL_24e3cdef531b4020989366eba22e09ef",
              "IPY_MODEL_aed9a064ab374cf2b4061f177f87cc03"
            ],
            "layout": "IPY_MODEL_017760bb2a3546259793eb5226c7d0fa"
          }
        },
        "90ea3ded66054cd9ad13c8f955ff5db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "912325d4971249ae838fa013a98dc92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e17b5c25bdb146b3831b9f6900c6cc52",
            "placeholder": "​",
            "style": "IPY_MODEL_2b46320894e44a8195d7e6fcf2e05216",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "936f7ede730642f7bc6ddfb6dbd8457c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99bf4c657d1a4bafa847e1ac5fb41733": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2b081a47094695b1aaad9804e1cf52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5af8555c158f442ab297494503f7b5f0",
            "placeholder": "​",
            "style": "IPY_MODEL_b1dc197e93a24d22b3b14a5a94a14e56",
            "value": " 28.1k/28.1k [00:00&lt;00:00, 2.18MB/s]"
          }
        },
        "9a44a1ceba204ecab13a47ab8d7625b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cb732b3ed1a48069fe683ee9e503004": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed9a064ab374cf2b4061f177f87cc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb575858b49e4d52bfa6ced2267508b7",
            "placeholder": "​",
            "style": "IPY_MODEL_90ea3ded66054cd9ad13c8f955ff5db6",
            "value": " 127085/127085 [00:00&lt;00:00, 336296.03 examples/s]"
          }
        },
        "b1dc197e93a24d22b3b14a5a94a14e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2a765d9f4974feaa8f6e258de704bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3627508576104e62acbdc7fafc752f22",
            "placeholder": "​",
            "style": "IPY_MODEL_6c1f5f6aaea44c15bf69ad3c015bd432",
            "value": "Generating train split: 100%"
          }
        },
        "b50113e248d64de39a9edd93d3d94b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6057770f57e4213aa39b6d598a62a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d31438f4994b6ba30cb181ccc54331": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7e2426ee92d4bcea4e14a348dbc0189": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41a3dc5666b749639abdf2d9cf84f40d",
            "max": 20985324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19b37d3a41a84204a9ec34fe7e147e45",
            "value": 20985324
          }
        },
        "d0e137eaf81d40f3ba7ce76999f3874c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7aaabe427fe46868f03392f8d565f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f1a2bd377414295a0c50686894e170c",
            "placeholder": "​",
            "style": "IPY_MODEL_499f02619b2e49859e4d33c436995291",
            "value": "README.md: 100%"
          }
        },
        "dfddf0c1fcd94cd5989f6a49b1a0f153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e17b5c25bdb146b3831b9f6900c6cc52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d4fe257a414a9fbd61e6deb4db215f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea624b6940df4e42ae305a0d39ce19bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb575858b49e4d52bfa6ced2267508b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66b0b60fc654586bf906c3a61823016": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6057770f57e4213aa39b6d598a62a7d",
            "placeholder": "​",
            "style": "IPY_MODEL_ea624b6940df4e42ae305a0d39ce19bc",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "f7d330f313a4496a8fc2e5c50aa63f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcd01726f1974bfbaf3df22e27298090": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
